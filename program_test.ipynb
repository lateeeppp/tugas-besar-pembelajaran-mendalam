{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65a7d0f3",
   "metadata": {},
   "source": [
    "## Install & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a35ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q timm mediapipe pillow-heif\n",
    "\n",
    "import os\n",
    "import json\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torchvision.transforms as T\n",
    "\n",
    "from pillow_heif import register_heif_opener\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "register_heif_opener()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc9c778",
   "metadata": {},
   "source": [
    "## Konfigurasi Path & Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2316378",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === DATA TEST ===\n",
    "TEST_DIR   = Path(\"./Test\")      # folder gambar test\n",
    "TEST_CSV   = Path(\"./test.csv\")  # csv: filename,label\n",
    "\n",
    "# === MODEL & MAPPING ===\n",
    "MODEL_DIR  = Path(\"./models\")\n",
    "DENSE_WEIGHTS_PATH = MODEL_DIR / \"densenet121_facecls.pth\"\n",
    "LABEL_MAPPING_PATH = MODEL_DIR / \"label_mapping.json\"\n",
    "\n",
    "# === OUTPUT ===\n",
    "WORK_DIR   = Path(\"./test_outputs\")\n",
    "WORK_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "IMG_SIZE     = 224\n",
    "BATCH_SIZE   = 32\n",
    "NUM_WORKERS  = 0\n",
    "RANDOM_SEED  = 42\n",
    "\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "if device.type == \"cuda\":\n",
    "    torch.cuda.manual_seed_all(RANDOM_SEED)\n",
    "\n",
    "VALID_EXTS = [\".jpg\", \".jpeg\", \".png\", \".webp\", \".bmp\", \".jfif\", \".heic\", \".heif\"]\n",
    "\n",
    "print(\"TEST_DIR :\", TEST_DIR.resolve())\n",
    "print(\"TEST_CSV :\", TEST_CSV.resolve())\n",
    "print(\"MODEL_DIR:\", MODEL_DIR.resolve())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ba700a",
   "metadata": {},
   "source": [
    "## Load Mapping, test.csv, Validasi Label, Build Test Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece561ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Cek keberadaan file penting ---\n",
    "assert LABEL_MAPPING_PATH.exists(), f\"Tidak menemukan {LABEL_MAPPING_PATH}\"\n",
    "assert TEST_DIR.exists(), f\"Tidak menemukan folder Test: {TEST_DIR}\"\n",
    "assert TEST_CSV.exists(), f\"Tidak menemukan file test.csv: {TEST_CSV}\"\n",
    "\n",
    "# --- Load mapping class <-> index dari training ---\n",
    "with open(LABEL_MAPPING_PATH, \"r\") as f:\n",
    "    mapping = json.load(f)\n",
    "\n",
    "class2idx = {k: int(v) for k, v in mapping[\"class2idx\"].items()}\n",
    "idx2class = {int(k): v for k, v in mapping[\"idx2class\"].items()}\n",
    "num_classes = len(class2idx)\n",
    "\n",
    "print(\"Total kelas (mapping):\", num_classes)\n",
    "print(\"Contoh mapping:\", list(class2idx.items())[:5])\n",
    "\n",
    "# --- Load test.csv ---\n",
    "df_test = pd.read_csv(TEST_CSV)\n",
    "assert \"filename\" in df_test.columns and \"label\" in df_test.columns, \\\n",
    "    \"test.csv harus memiliki kolom 'filename' dan 'label'.\"\n",
    "\n",
    "df_test[\"filename\"] = df_test[\"filename\"].astype(str)\n",
    "df_test[\"label\"]    = df_test[\"label\"].astype(str)\n",
    "\n",
    "# --- VALIDASI: pastikan semua label test.csv ada di mapping training ---\n",
    "labels_in_test    = set(df_test[\"label\"].tolist())\n",
    "labels_in_mapping = set(class2idx.keys())\n",
    "\n",
    "unknown_labels = sorted(labels_in_test - labels_in_mapping)\n",
    "\n",
    "print(f\"[INFO] Total label unik di test.csv   : {len(labels_in_test)}\")\n",
    "print(f\"[INFO] Total label unik di mapping    : {len(labels_in_mapping)}\")\n",
    "\n",
    "if unknown_labels:\n",
    "    print(\"\\n[WARNING] Terdapat label di test.csv yang TIDAK ditemukan di mapping training:\")\n",
    "    for lbl in unknown_labels:\n",
    "        print(\"   -\", repr(lbl))\n",
    "\n",
    "    raise ValueError(\n",
    "        \"\\nERROR: Ada label di test.csv yang tidak ada di label_mapping.json.\\n\"\n",
    "        \"Silakan cek kembali nama label test.csv agar sesuai dengan nama folder Train.\\n\"\n",
    "        \"Masalah ini biasanya terjadi karena perbedaan spasi, titik, underscore, kapitalisasi, atau typo.\"\n",
    "    )\n",
    "\n",
    "print(\"[INFO] Validasi label test.csv selesai. Semua label cocok dengan mapping. âœ”\")\n",
    "\n",
    "# --- Build list path & label index untuk dataset test ---\n",
    "test_paths = []\n",
    "test_labels = []\n",
    "\n",
    "for _, row in df_test.iterrows():\n",
    "    fname = row[\"filename\"]\n",
    "    label_name = row[\"label\"]\n",
    "    fpath = TEST_DIR / fname\n",
    "\n",
    "    if not fpath.exists():\n",
    "        print(f\"[WARNING] File tidak ditemukan: {fpath}, skip.\")\n",
    "        continue\n",
    "\n",
    "    ext = fpath.suffix.lower()\n",
    "    if ext not in VALID_EXTS:\n",
    "        print(f\"[WARNING] Ekstensi tidak didukung: {fpath}, skip.\")\n",
    "        continue\n",
    "\n",
    "    label_idx = class2idx[label_name]\n",
    "    test_paths.append(str(fpath))\n",
    "    test_labels.append(label_idx)\n",
    "\n",
    "test_paths  = np.array(test_paths)\n",
    "test_labels = np.array(test_labels, dtype=np.int64)\n",
    "\n",
    "print(\"Total data test terbaca:\", len(test_paths))\n",
    "print(\"Contoh path:\", test_paths[:3])\n",
    "print(\"Contoh label idx:\", test_labels[:3])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c46d97",
   "metadata": {},
   "source": [
    "## Helper Baca Gambar & Face Crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5381fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_face_detection = mp.solutions.face_detection\n",
    "\n",
    "def read_image_bgr(path):\n",
    "    path = str(path)\n",
    "    ext = os.path.splitext(path)[1].lower()\n",
    "    if ext in [\".heic\", \".heif\"]:\n",
    "        img = Image.open(path).convert(\"RGB\")\n",
    "        img = np.array(img)[:, :, ::-1]  # RGB -> BGR\n",
    "        return img\n",
    "\n",
    "    img = cv2.imread(path)\n",
    "    if img is None:\n",
    "        img_pil = Image.open(path).convert(\"RGB\")\n",
    "        img = np.array(img_pil)[:, :, ::-1]\n",
    "    return img\n",
    "\n",
    "\n",
    "def crop_face_mediapipe(path, margin=0.2):\n",
    "    img_bgr = read_image_bgr(path)\n",
    "    h, w, _ = img_bgr.shape\n",
    "    img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    with mp_face_detection.FaceDetection(\n",
    "        model_selection=1,\n",
    "        min_detection_confidence=0.5\n",
    "    ) as face_det:\n",
    "        results = face_det.process(img_rgb)\n",
    "\n",
    "        if not results.detections:\n",
    "            return Image.fromarray(img_rgb)\n",
    "\n",
    "        detections = sorted(\n",
    "            results.detections,\n",
    "            key=lambda d: d.score[0] if d.score else 0,\n",
    "            reverse=True\n",
    "        )\n",
    "        det = detections[0]\n",
    "        bbox = det.location_data.relative_bounding_box\n",
    "\n",
    "        x_min = int(bbox.xmin * w)\n",
    "        y_min = int(bbox.ymin * h)\n",
    "        box_w = int(bbox.width * w)\n",
    "        box_h = int(bbox.height * h)\n",
    "\n",
    "        cx = x_min + box_w // 2\n",
    "        cy = y_min + box_h // 2\n",
    "\n",
    "        half_w = int(box_w * (1 + margin) / 2)\n",
    "        half_h = int(box_h * (1 + margin) / 2)\n",
    "\n",
    "        x1 = max(0, cx - half_w)\n",
    "        x2 = min(w, cx + half_w)\n",
    "        y1 = max(0, cy - half_h)\n",
    "        y2 = min(h, cy + half_h)\n",
    "\n",
    "        crop = img_rgb[y1:y2, x1:x2]\n",
    "        if crop.size == 0:\n",
    "            return Image.fromarray(img_rgb)\n",
    "\n",
    "        return Image.fromarray(crop)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f3c280",
   "metadata": {},
   "source": [
    "## Transform & Dataset Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a04065c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transform = T.Compose([\n",
    "    T.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.5, 0.5, 0.5],\n",
    "                std=[0.5, 0.5, 0.5]),\n",
    "])\n",
    "\n",
    "class FaceTestDataset(Dataset):\n",
    "    def __init__(self, paths, labels, transform=None, use_face_crop=True):\n",
    "        self.paths = paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.use_face_crop = use_face_crop\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.paths[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if self.use_face_crop:\n",
    "            img_pil = crop_face_mediapipe(path)\n",
    "        else:\n",
    "            img_bgr = read_image_bgr(path)\n",
    "            img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
    "            img_pil = Image.fromarray(img_rgb)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img_tensor = self.transform(img_pil)\n",
    "        else:\n",
    "            img_tensor = T.ToTensor()(img_pil)\n",
    "\n",
    "        fname = os.path.basename(path)\n",
    "        return img_tensor, label, fname\n",
    "\n",
    "\n",
    "test_dataset = FaceTestDataset(\n",
    "    test_paths,\n",
    "    test_labels,\n",
    "    transform=test_transform,\n",
    "    use_face_crop=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "print(\"Jumlah batch test:\", len(test_loader))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21210943",
   "metadata": {},
   "source": [
    "## Metrics (Tanpa sklearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad7a148",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(y_true, y_pred, num_classes):\n",
    "    cm = np.zeros((num_classes, num_classes), dtype=np.int64)\n",
    "    for t, p in zip(y_true, y_pred):\n",
    "        cm[t, p] += 1\n",
    "\n",
    "    acc = np.trace(cm) / np.sum(cm) if np.sum(cm) > 0 else 0.0\n",
    "\n",
    "    precision_per_class = []\n",
    "    recall_per_class = []\n",
    "    f1_per_class = []\n",
    "\n",
    "    for c in range(num_classes):\n",
    "        tp = cm[c, c]\n",
    "        fp = cm[:, c].sum() - tp\n",
    "        fn = cm[c, :].sum() - tp\n",
    "\n",
    "        prec = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
    "        rec  = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "        f1   = 2 * prec * rec / (prec + rec) if (prec + rec) > 0 else 0.0\n",
    "\n",
    "        precision_per_class.append(prec)\n",
    "        recall_per_class.append(rec)\n",
    "        f1_per_class.append(f1)\n",
    "\n",
    "    precision_per_class = np.array(precision_per_class)\n",
    "    recall_per_class    = np.array(recall_per_class)\n",
    "    f1_per_class        = np.array(f1_per_class)\n",
    "\n",
    "    support = cm.sum(axis=1)\n",
    "    total = support.sum() if support.sum() > 0 else 1\n",
    "    weights = support / total\n",
    "\n",
    "    precision_weighted = np.sum(precision_per_class * weights)\n",
    "    recall_weighted    = np.sum(recall_per_class * weights)\n",
    "    f1_weighted        = np.sum(f1_per_class * weights)\n",
    "\n",
    "    precision_macro = precision_per_class.mean()\n",
    "    recall_macro    = recall_per_class.mean()\n",
    "    f1_macro        = f1_per_class.mean()\n",
    "\n",
    "    return {\n",
    "        \"confusion_matrix\": cm,\n",
    "        \"accuracy\": acc,\n",
    "        \"precision_weighted\": precision_weighted,\n",
    "        \"recall_weighted\": recall_weighted,\n",
    "        \"f1_weighted\": f1_weighted,\n",
    "        \"precision_macro\": precision_macro,\n",
    "        \"recall_macro\": recall_macro,\n",
    "        \"f1_macro\": f1_macro,\n",
    "    }\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(cm, title=\"Confusion Matrix\"):\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, cmap=\"Blues\")\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50242224",
   "metadata": {},
   "source": [
    "## Build DenseNet121 (harus sama dengan training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7217858c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "\n",
    "def build_densenet121(num_classes):\n",
    "    model = timm.create_model(\n",
    "        \"densenet121\",\n",
    "        pretrained=False,        # di TEST: False, pakai weight .pth\n",
    "        num_classes=num_classes\n",
    "    )\n",
    "    return model\n",
    "\n",
    "densenet_model = build_densenet121(num_classes).to(device)\n",
    "print(\"DenseNet121 params (M):\", sum(p.numel() for p in densenet_model.parameters()) / 1e6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3385213f",
   "metadata": {},
   "source": [
    "## Load Saved Weights DenseNet121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95b98c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert DENSE_WEIGHTS_PATH.exists(), f\"Tidak menemukan: {DENSE_WEIGHTS_PATH}\"\n",
    "\n",
    "dense_state = torch.load(DENSE_WEIGHTS_PATH, map_location=device)\n",
    "densenet_model.load_state_dict(dense_state)\n",
    "densenet_model.eval()\n",
    "\n",
    "print(\"Loaded DenseNet121 from:\", DENSE_WEIGHTS_PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2cfe393",
   "metadata": {},
   "source": [
    "## Fungsi Evaluasi Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a39b92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate_on_loader(model, loader, device):\n",
    "    model.eval()\n",
    "    all_true = []\n",
    "    all_pred = []\n",
    "    all_fname = []\n",
    "\n",
    "    for imgs, labels, fnames in loader:\n",
    "        imgs = imgs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        logits = model(imgs)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "\n",
    "        all_true.extend(labels.cpu().numpy().tolist())\n",
    "        all_pred.extend(preds.cpu().numpy().tolist())\n",
    "        all_fname.extend(list(fnames))\n",
    "\n",
    "    all_true = np.array(all_true)\n",
    "    all_pred = np.array(all_pred)\n",
    "    return all_true, all_pred, all_fname\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ff14d0",
   "metadata": {},
   "source": [
    "## Evaluasi DenseNet121 + jawaban.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4269a290",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Evaluasi DenseNet121 di TEST SET ===\")\n",
    "\n",
    "y_true_dense, y_pred_dense, fnames_dense = evaluate_on_loader(\n",
    "    densenet_model, test_loader, device\n",
    ")\n",
    "\n",
    "metrics_dense = compute_metrics(y_true_dense, y_pred_dense, num_classes)\n",
    "\n",
    "print(f\"Accuracy          : {metrics_dense['accuracy']:.4f}\")\n",
    "print(f\"Precision (wgt)   : {metrics_dense['precision_weighted']:.4f}\")\n",
    "print(f\"Recall    (wgt)   : {metrics_dense['recall_weighted']:.4f}\")\n",
    "print(f\"F1-score (wgt)    : {metrics_dense['f1_weighted']:.4f}\")\n",
    "print(f\"Precision (macro) : {metrics_dense['precision_macro']:.4f}\")\n",
    "print(f\"Recall    (macro) : {metrics_dense['recall_macro']:.4f}\")\n",
    "print(f\"F1-score (macro)  : {metrics_dense['f1_macro']:.4f}\")\n",
    "\n",
    "plot_confusion_matrix(metrics_dense[\"confusion_matrix\"],\n",
    "                      title=\"Confusion Matrix - DenseNet121 (Test Set)\")\n",
    "\n",
    "# Simpan full pred + jawaban submission\n",
    "df_dense = pd.DataFrame({\n",
    "    \"filename\": fnames_dense,\n",
    "    \"true_label_idx\": y_true_dense,\n",
    "    \"true_label_name\": [idx2class[int(i)] for i in y_true_dense],\n",
    "    \"pred_label_idx\": y_pred_dense,\n",
    "    \"pred_label_name\": [idx2class[int(i)] for i in y_pred_dense],\n",
    "})\n",
    "\n",
    "jawaban_dense_full = WORK_DIR / \"jawaban_densenet121_full.csv\"\n",
    "jawaban_dense_sub  = WORK_DIR / \"jawaban_densenet121_submit.csv\"\n",
    "\n",
    "df_dense.to_csv(jawaban_dense_full, index=False)\n",
    "df_dense[[\"filename\", \"pred_label_name\"]].rename(\n",
    "    columns={\"pred_label_name\": \"label\"}\n",
    ").to_csv(jawaban_dense_sub, index=False)\n",
    "\n",
    "print(\"Saved DenseNet full predictions  :\", jawaban_dense_full)\n",
    "print(\"Saved DenseNet jawaban.csv (sub) :\", jawaban_dense_sub)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
